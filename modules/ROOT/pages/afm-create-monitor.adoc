= Create a Monitor
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]

You can create a monitor by filling in fields if you do not know how to write tests in the Behavior Driven Development (BDD) test-writing language or how to use the BAT CLI. This method of creating a monitor creates a test that tests one or more endpoints, and schedules the test to run at intervals that you specify.

After every interval, you can view the results of the test and statistics about API performance.


== Before You Begin

* Determine whether you want to monitor the endpoints in one or more public APIs, one or more private APIs, or a mix of both public APIs and private APIs.
+
For details, see xref:afm-monitoring-public-apis.adoc[Monitoring the Endpoints of Public APIs] and xref:afm-monitoring-private-apis.adoc[Monitoring the Endpoints of Private APIs and Mixes of Both Public and Private APIs].
* Ensure that your user ID has the "Anypoint Monitoring User" permission.
+
An administrator for your organization can grant you this permission in Anypoint Access Management.
* Determine which endpoints you want to test and the REST methods that you want to test them with.
* Decide upon the return codes that you expect the methods to return.
* Figure out the frequency at which you would like the monitor to test the endpoints.
+
The shortest interval is every fifteen minutes. You can also choose to run the monitor hourly, daily, weekly, or monthly. The schedule begins immediately after you create the monitor. You can schedule another monitor later for the same test suite that is more detailed, if you prefer. You can also modify the schedule after you create the monitor, if you want to specify any of these options:
** Set an hourly schedule to start at a certain number of minutes after the hour begins.
** Set a daily, weekly, or monthly schedule to start at a certain time of day.
* Decide whether you would like the request messages to include additional header information.
* Obtain one of the following pieces of information, if you would like to send results of failed tests to one of these reporting tools:
+
|===
|Reporting Tool |Required Information

|NewRelic
|License Key

|PagerDuty
|RoutingKey

|Slack
|Webhook

|SumoLogic
|Endpoint

|Email
|Email address
|===


== Procedure
To create a monitor:

. In the *Functional Monitoring* section of Anypoint Monitoring, click *Create Monitor* in the top-right corner of your browser window.
. In the *Monitor Setup* section, specify the name of the monitor, the location from which to run the test, how often to run the test, and whether to validate SSL certificates.
.. Specify a name for the monitor.
.. Select the location from which to run the test.
+
Public locations are grouped separately from private locations in the list. You can create a private location by clicking an option in the list.
.. Specify the intervals at which you want the monitor to run the test.
+
The interval that you select begins when you click *Create Monitor* at the end of this procedure.
.. Toggle the *SSL Certificate Validation* switch off if the endpoints that your monitor will test use self-signed certificates.
+
If they do use self-signed certificates and you do not toggle this switch off, tests against those endpoints fail.
+
** If the toggle is on, all endpoints that use SSL certificates must have certificates that are signed by a trusted authority.
** If the toggle is off, all endpoints that use SSL certificates must be self-signed.
+
To test a combination of endpoints that use trusted SSL certificates and endpoints that use self-signed certificates, create two separate monitors: one for testing the first group of endpoints, the other for testing the second group of endpoints.
. Click *Next*.
. In the *Endpoints* section, specify one or more endpoints to include in the test, the HTTP methods to use to test them, the status codes that each endpoint is expected to return, and any assertions that you want to include for each endpoint.
. Click *Next*.
. If you want to be notified of failed tests, select one or more reporters.
. Click *Create monitor*.

== Result

The monitor that you created is listed at the top of the list of your monitors. API Functional Monitoring begins counting down the interval of time that you selected. When the interval expires, the test is run.

[IMPORTANT]
====
Tests fail when they take more than 120 seconds to run. As a workaround, you can split a long-running test into multiple tests. Download the monitor, split the test across multiple monitors in the BAT CLI, run and time each test to be sure that it is under 120 seconds, and then upload the monitors.

If you do not want to split a long-running test, download the monitor and run it from the BAT CLI.
====

== What to do next

After the test is complete, two things happen:

* The countdown of the interval begins again.
* After the test runs for the first time, a summary of the results appears under *Endpoint* in the list entry for the monitor. The summary is something similar to "1 Failed" or "1 Failed/3 Passed", with the sum of the numbers in the summary indicating the number of endpoints in the test. Click the list entry for the monitor to view the details of the test results.


== See Also

* xref:afm-monitoring-public-apis.adoc[Monitoring the Endpoints of Public APIs]
* xref:afm-monitoring-private-apis.adoc[Monitoring the Endpoints of Private APIs and Mixes of Both Public and Private APIs]
* xref:afm-edit-test.adoc[Edit a Monitor]
* xref:afm-delete-monitor.adoc[Delete a Monitor]
* xref:bat-top.adoc[API Functional Monitoring with the Blackbox Automated Testing (BAT) CLI]
